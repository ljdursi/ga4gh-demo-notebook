{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of GA4GH Variant + Read API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GA4GH examples trimmed from a wider [GA4GH demo](https://github.com/david4096/bioapi-examples/blob/master/python_notebooks/1kg.ipynb).  We're using the standard reference server we've stood up here at HSC, but the full 1000genomes data set is also available at `baseURL = \"http://1kgenomes.ga4gh.org\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ga4gh.client\n",
    "from __future__ import print_function\n",
    "\n",
    "baseURL = \"http://ga4gh.dursi.ca:8000\"\n",
    "client = ga4gh.client.HttpClient(baseURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data - whether variants, reads, or references - are bundled together in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets\n",
      "Name: GA4GH_DEM\n"
     ]
    }
   ],
   "source": [
    "datasets = list(client.search_datasets())\n",
    "print(\"Datasets\")\n",
    "for dataset in datasets:\n",
    "    print(\"Name: {}\".format(dataset.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just have the one dataset, that of a subset of the 1kG project; we can set what variantsets are contained within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariantSets\n",
      "Name: phase3-release\n"
     ]
    }
   ],
   "source": [
    "dataset = client.get_dataset(datasets[0].id)\n",
    "variantSets = list(client.search_variant_sets(dataset.id))\n",
    "print(\"VariantSets\")\n",
    "for variantSet in variantSets:\n",
    "    print(\"Name: {}\".format(variantSet.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WyJHQTRHSF9ERU0iLCJ2cyIsInBoYXNlMy1yZWxlYXNlIl0\n"
     ]
    }
   ],
   "source": [
    "variantSetId = variantSets[0].id\n",
    "variantSet = client.get_variant_set(variantSetId)\n",
    "print(variantSet.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using that variantid, we can find the callsets associated with the variant set; the callsets belong to a particular sample, called a particular way.  If multiple callers were run, each sample might have two callsets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CallSets\n",
      "0, Name: HG00096\n",
      "1, Name: HG00533\n",
      "2, Name: HG00534\n"
     ]
    }
   ],
   "source": [
    "callSets = list(client.search_call_sets(variantSetId))\n",
    "print(\"CallSets\")\n",
    "for i, callSet in enumerate(callSets):\n",
    "    print(\"{}, Name: {}\".format(i, callSet.name))\n",
    "    if i > 4:\n",
    "        print(\"... and so on, for a total of {} callsets\".format(len(callSets)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variants\n",
      "Reference Name: 1, Start: 10176, Name: rs367896724\n",
      "Reference Name: 1, Start: 10234, Name: rs540431307\n"
     ]
    }
   ],
   "source": [
    "variants = list(client.search_variants(variantSetId, start=10000, end=10300, \n",
    "                                       reference_name = \"1\",\n",
    "                                       call_set_ids=[callset.id for callset in callSets]))\n",
    "print(\"Variants\")\n",
    "for variant in variants:\n",
    "    print(\"Reference Name: {}, Start: {}, Name: {}\".format(variant.reference_name, \n",
    "                                                           variant.start, variant.names[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs367896724 A [u'AC'] string_value: \"0.425318986177\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ex = variants[0]\n",
    "print(ex.names[0], ex.reference_bases, ex.alternate_bases, ex.info[\"AF\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This variant is then called (or not) across all the callsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of calls: 3\n",
      "call_set_name: \"HG00096\"\n",
      "call_set_id: \"WyJHQTRHSF9ERU0iLCJ2cyIsInBoYXNlMy1yZWxlYXNlIiwiSEcwMDA5NiJd\"\n",
      "genotype: 1\n",
      "genotype: 0\n",
      "phaseset: \"True\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of calls: {}\".format(len(ex.calls)))\n",
    "print(ex.calls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homozygous ref = 2/3 (66.6%)\n",
      "Heterozygous alt 1/3 (33.3%)\n",
      "Homozygous alt = 0/3 (0.0%))\n"
     ]
    }
   ],
   "source": [
    "altcounts = [0,0,0]\n",
    "for call in ex.calls:\n",
    "    nalt = call.genotype[0] + call.genotype[1]\n",
    "    altcounts[nalt] += 1\n",
    "tot = sum(altcounts)\n",
    "print(\"Homozygous ref = {}/{} ({}%)\\nHeterozygous alt {}/{} ({}%)\\nHomozygous alt = {}/{} ({}%))\".\\\n",
    "     format(altcounts[0], tot, int(1000*altcounts[0]*1./tot)/10.,\n",
    "            altcounts[1], tot, int(1000*altcounts[1]*1./tot)/10.,\n",
    "            altcounts[2], tot, int(1000*altcounts[2]*1./tot)/10.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the first call set name corresponding to a het alt call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HG00096\n"
     ]
    }
   ],
   "source": [
    "het_alts = [call.call_set_name for call in ex.calls \n",
    "            if sum(call.genotype) == 1]\n",
    "print(het_alts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case (but not necessarily in general!) the readgroupset names are the same as the call set names, so we can look at the reads corresponding to these calls.  Because reads are aligned to the reference, we need the reference id.  Note too that we have to go through all the read group sets to find the one we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: \"WyJHUkNoMzciLCIxIl0\"\n",
      "length: 138395\n",
      "md5checksum: \"bb07c91cda4645ad8e75e375e3d6e5eb\"\n",
      "name: \"1\"\n",
      "\n",
      "Read group set : HG00096\n"
     ]
    }
   ],
   "source": [
    "reference_set = list(client.search_reference_sets())[0]\n",
    "references = [r for r in client.search_references(reference_set_id=reference_set.id)]\n",
    "print(references[0])\n",
    "\n",
    "read_group_sets = list(client.search_read_group_sets(dataset_id=dataset.id))\n",
    "read_group_set = [rgs for rgs in read_group_sets if rgs.name in het_alts][0]\n",
    "print(\"Read group set : {}\".format(read_group_set.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the sequences in the read sets corresponding to this variant in this patient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ref: CCTAACCCTAACCTAACCCTA\n",
      "     CCTAACCCTAACCCTAACCCTA\n",
      "     ACCCTAACCCTAACCCTAAACC\n",
      "     CCTAACCCTAACCTAACCCTAA\n",
      "     CCTAACCCAACCCTAACCCTAA\n",
      "     CCTAACCCTAACCCTGACCCTA\n",
      "     CCTAACCCTAACCTAACCCTAA\n",
      "     CCTAACCCTAACCCCAACCCCA\n"
     ]
    }
   ],
   "source": [
    "start = ex.start-10\n",
    "end = ex.end+10\n",
    "length = end-start+1\n",
    "\n",
    "print(\"Ref: \"+ client.list_reference_bases(references[0].id, start=start, end=end))\n",
    "for read_group in read_group_set.read_groups:\n",
    "    sequences = list(client.search_reads(read_group_ids=[read_group.id], \n",
    "                                        start=start, end=end,\n",
    "                                        reference_id=references[0].id))\n",
    "    for sequence in sequences:\n",
    "        seqstart = sequence.alignment.position.position\n",
    "        pos_strand = sequence.alignment.position.strand == 2\n",
    "        if seqstart <= start and pos_strand:\n",
    "            print(\"     \"+sequence.aligned_sequence[start-seqstart:start-seqstart+length])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExAC\n",
    "\n",
    "ExAC also has a [rest API](https://github.com/hms-dbmi/exac_browser), but it only handles variants and their annotations, and there isn't a cute python API wrapper yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-13000-20000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "exac_base_url = \"http://exac.hms.harvard.edu/rest/\"\n",
    "chrom = \"1\"\n",
    "start = \"13000\"\n",
    "stop = \"20000\"\n",
    "region_id = chrom + \"-\" + start + \"-\" + stop\n",
    "print(region_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'allele_count': 2, u'pos': 13372, u'quality_metrics': {u'FS': u'0.000', u'MQRankSum': u'0.727', u'InbreedingCoeff': u'-0.0844', u'VQSLOD': u'-1.687e+00', u'BaseQRankSum': u'0.727', u'MQ': u'35.72', u'QD': u'23.42', u'ReadPosRankSum': u'0.727', u'DP': u'139843', u'ClippingRankSum': u'1.15'}, u'variant_id': u'1-13372-G-C', u'alt': u'C', u'pop_homs': {u'European (Non-Finnish)': 0, u'East Asian': 0, u'Other': 0, u'African': 0, u'Latino': 0, u'South Asian': 1, u'European (Finnish)': 0}, u'pop_acs': {u'European (Non-Finnish)': 0, u'East Asian': 0, u'Other': 0, u'African': 0, u'Latino': 0, u'South Asian': 2, u'European (Finnish)': 0}, u'category': u'synonymous_variant', u'allele_freq': 0.00023719165085388995, u'major_consequence': u'splice_region_variant', u'HGVSc': u'n.412G>C', u'rsid': u'.', u'ref': u'G', u'HGVSp': u'', u'hom_count': 1, u'chrom': u'1', u'allele_num': 8432, u'pop_ans': {u'European (Non-Finnish)': 2116, u'East Asian': 254, u'Other': 90, u'African': 770, u'Latino': 134, u'South Asian': 5052, u'European (Finnish)': 16}, u'filter': u'PASS', u'flags': [], u'HGVS': u'n.412G>C', u'CANONICAL': u''}\n",
      "Variant allele frequencies: \n",
      "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 7, 8, 9, 13, 17, 17, 21, 22, 23, 23, 24, 31, 49, 55, 59, 75, 103, 105, 140, 188, 214, 261, 398, 455, 988, 1327, 1506]\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\n",
    "        exac_base_url + \"region/variants_in_region/\" + region_id)\n",
    "variants = response.json()\n",
    "print(variants[0])\n",
    "\n",
    "print(\"Variant allele frequencies: \")\n",
    "print(sorted([variant['allele_count'] for variant in variants]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also has somewhat wider search functionality, with syntactic sugar for searching by gene/transcript, or prioritizing (but not filtering) responses by consenquence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possibly_damaging(0.693)\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\n",
    "            exac_base_url + \"variant/consequences/\"+\"20-76735-A-T\")\n",
    "variants = response.json()\n",
    "print(variants['missense_variant']['ENSG00000178591'][0]['PolyPhen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'allele_count': 1, u'pos': 55505475, u'quality_metrics': {u'FS': u'2.276', u'MQRankSum': u'-8.110e-01', u'InbreedingCoeff': u'-0.0361', u'VQSLOD': u'-2.094e+00', u'BaseQRankSum': u'-1.093e+00', u'MQ': u'60.00', u'QD': u'5.42', u'ReadPosRankSum': u'-3.120e-01', u'DP': u'695607', u'ClippingRankSum': u'0.555'}, u'variant_id': u'1-55505475-C-T', u'alt': u'T', u'pop_homs': {u'European (Non-Finnish)': 0, u'East Asian': 0, u'Other': 0, u'African': 0, u'Latino': 0, u'South Asian': 0, u'European (Finnish)': 0}, u'pop_acs': {u'European (Non-Finnish)': 1, u'East Asian': 0, u'Other': 0, u'African': 0, u'Latino': 0, u'South Asian': 0, u'European (Finnish)': 0}, u'category': u'other_variant', u'allele_freq': 3.2634945499641017e-05, u'major_consequence': u'5_prime_UTR_variant', u'HGVSc': u'c.-36C>T', u'rsid': u'.', u'ref': u'C', u'HGVSp': u'', u'hom_count': 0, u'chrom': u'1', u'allele_num': 30642, u'pop_ans': {u'European (Non-Finnish)': 14444, u'East Asian': 2332, u'Other': 204, u'African': 3508, u'Latino': 1110, u'South Asian': 8684, u'European (Finnish)': 360}, u'filter': u'PASS', u'flags': [], u'HGVS': u'', u'CANONICAL': u'YES'}\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\n",
    "            exac_base_url + \"awesome?query=\"+\"PCSK9\"+\"&service=variants_in_gene\")\n",
    "variants = response.json()\n",
    "print(variants[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "Python 2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
